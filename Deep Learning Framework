{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOKteR3K7iExKuOm1+GJiYb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Theory Questions"],"metadata":{"id":"9H8RcJo3PrTq"}},{"cell_type":"markdown","source":["1.  What is TensorFlow 2.0, and how is it different from TensorFlow 1.x?\n","\n","-> TensorFlow 2.0 is a newer and more user-friendly version of TensorFlow, which is a popular tool used to build and train machine learning models.\n","\n","The main difference between TensorFlow 2.0 and the older version (1.x) is that TensorFlow 2.0 is much easier to use. In the older version, writing code was more complex and confusing. You had to define everything first and then run it later, which made debugging and learning harder.\n","\n","But in TensorFlow 2.0:\n","- It runs code step-by-step (called \"eager execution\"), so you see results right away.\n","- It uses Keras as the main way to build models, which is simpler and more readable.\n","- Many older, confusing functions were removed or updated to make things cleaner.\n","\n","In short, TensorFlow 2.0 was designed to make building and training models feel more natural and beginner-friendly.\n"],"metadata":{"id":"pyxDAw6bPLtJ"}},{"cell_type":"markdown","source":["*2*. How do you install TensorFlow 2.0?\n","\n","-> pip install tensorflow\n","\n","\n"],"metadata":{"id":"ZBlkvrV5QNDh"}},{"cell_type":"markdown","source":["3. What is the primary function of the tf.function in TensorFlow 2.0?\n","\n","-> The main job of tf.function in TensorFlow 2.0 is to make your code run faster.\n","\n","When you add @tf.function above your function, TensorFlow takes your Python code and converts it into a faster, graph-style code behind the scenes. This speeds things up—especially for large models or lots of data.\n","\n"],"metadata":{"id":"eXThhtbZZAJR"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","@tf.function\n","def add(a, b):\n","    return a + b\n"],"metadata":{"id":"P8c_A9MgaHfv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. What is the purpose of the Model class in TensorFlow 2.0?\n","\n","-> The purpose of the Model class in TensorFlow 2.0 is to help you build and manage a machine learning model easily.\n","\n","It's like a container that holds:\n","- The layers of your model\n","- The forward pass (how the input moves through the layers)\n","- Training and evaluation logic"],"metadata":{"id":"0yws6g28iKak"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","# Define the model (same as before)\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Dense\n","\n","class MyModel(Model):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.dense1 = Dense(10, activation='relu')\n","        self.dense2 = Dense(1)\n","\n","    def call(self, inputs):\n","        x = self.dense1(inputs)\n","        return self.dense2(x)\n","\n","# Create the model\n","model = MyModel()\n","\n","# Make a sample input (like one row of data with 5 features)\n","sample_input = tf.constant([[1.0, 2.0, 3.0, 4.0, 5.0]])\n","\n","# Call the model on the input and print the result\n","output = model(sample_input)\n","print(\"Model Output:\", output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AFHyvmq1i2df","executionInfo":{"status":"ok","timestamp":1752305511944,"user_tz":-330,"elapsed":2883,"user":{"displayName":"Aditi Sahay","userId":"17710093122257315532"}},"outputId":"3e1db300-9d37-4902-b827-a0f78d69df6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Output: tf.Tensor([[6.763954]], shape=(1, 1), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["5. How do you create a neural network using TensorFlow 2.0?\n","\n","-> To create a neural network using TensorFlow 2.0, we follow these basic steps:\n","\n","- Importing the required libraries: First, we import TensorFlow and necessary modules to build the model.\n","\n","- Building the model architecture: We define the structure of the neural network by adding layers using the Sequential API or Model class.\n","\n","- Compiling the model: We specify the optimizer, loss function, and metrics to prepare the model for training.\n","\n","- Preparing the data: We load and organize the input (features) and output (labels) data.\n","\n","- Training the model: We train the model by passing the data through it multiple times (called epochs) so it can learn.\n","\n","- Making predictions: After training, we use the model to make predictions on new or unseen data.\n","\n"],"metadata":{"id":"4sb2YyO9gbzj"}},{"cell_type":"markdown","source":["6. What is the importance of Tensor Space in TensorFlow?\n","\n","-> In TensorFlow, tensor space refers to the way data is stored and handled in the form of tensors. Tensors are just multi-dimensional arrays (like numbers in rows and columns), and they are the basic units through which data flows in a neural network.\n","\n","The importance of tensor space is:\n","- It helps in organizing data properly, whether it is a number, a list, an image, or even a batch of data.\n","- It allows mathematical operations to be done efficiently using GPUs or TPUs.\n","- It keeps the structure of data clear, so TensorFlow knows how to move data through layers during training and prediction."],"metadata":{"id":"u3oLhxMVhSFj"}},{"cell_type":"markdown","source":["7. How can TensorBoard be integrated with TensorFlow 2.0?\n","\n","-> TensorBoard is a tool used to visualize and track the training process of a model. It helps us see things like loss, accuracy, and how the model is improving over time.\n","\n","To integrate TensorBoard with TensorFlow 2.0, we follow these steps:\n","\n","- Import TensorBoard from TensorFlow.\n","- Create a folder (called a log directory) where the training details will be saved.\n","- While training the model using model.fit(), we mention this log directory so TensorFlow knows where to store the progress.\n","- After training, we open TensorBoard in the browser using a command like tensorboard --logdir=folder_name.\n","\n"],"metadata":{"id":"nY_LvSKmhiTL"}},{"cell_type":"markdown","source":["8. What is the purpose of TensorFlow Playground?\n","\n","-> TensorFlow Playground is a web-based tool that helps us understand how neural networks work. It lets us experiment with simple models directly in the browser — without writing any code.\n","\n","The main purpose is to visualize and learn how changing things like layers, neurons, activation functions, and learning rates affects model performance. It's mostly used for learning and teaching the basics of deep learning in an easy and interactive way."],"metadata":{"id":"AjN1WQB3hiiu"}},{"cell_type":"markdown","source":["9. What is Netron, and how is it useful for deep learning models?\n","\n","-> Netron is a tool used to **visualize** deep learning models. It helps us see the structure of a model—like its layers, shapes, and connections—in a clear and easy-to-understand way.\n","\n","It supports many model formats like TensorFlow, Keras, PyTorch, ONNX, etc. This makes it useful for:\n","- Understanding how a model is built\n","- Debugging mistakes in model design\n","- Explaining the model to others visually\n","\n","Netron helps us look inside a deep learning model without digging into code.\n","\n"],"metadata":{"id":"OdzWkSyNhir6"}},{"cell_type":"markdown","source":["10. What is the difference between TensorFlow and PyTorch?\n","\n","-> TensorFlow and PyTorch are both popular tools used to build and train machine learning and deep learning models. The main differences between them are:\n","\n","- Ease of use:\n","PyTorch is easier to understand and feels more like regular Python. TensorFlow was harder earlier, but TensorFlow 2.0 made it simpler.\n","\n","- Execution style:\n","PyTorch runs code step by step (called eager execution), which makes it easier to debug. TensorFlow also supports this now, but PyTorch started with it.\n","\n","- Popularity in research vs. industry:\n","PyTorch is more popular in research because it's flexible. TensorFlow is widely used in industry because it has better tools for production and deployment.\n","\n","- Visualization:\n","TensorFlow has built-in tools like TensorBoard to visualize training. PyTorch needs external tools for the same.\n","\n"],"metadata":{"id":"DZ-OOvNKhi1C"}},{"cell_type":"markdown","source":["11. How do you install PyTorch?\n","\n","-> To install PyTorch, we use command: **pip install torch torchvision**"],"metadata":{"id":"sKmt7fGJhi45"}},{"cell_type":"markdown","source":["12. What is the basic structure of a PyTorch neural network?\n","\n","-> The basic structure of a PyTorch neural network includes the following parts:\n","\n","- Importing libraries: First, we import PyTorch and other required modules.\n","- Defining the model class: We create a class that inherits from nn.Module. Inside this class:\n","  - We define the layers in the __init__ function.\n","  - We define how data flows through the layers in the forward() function.\n","\n","- Creating an object of the model: We create the model by calling our class.\n","\n","- Choosing a loss function and optimizer: This tells the model how to learn and improve.\n","\n","- Training the model: We loop through the data, make predictions, calculate the loss, and update the weights."],"metadata":{"id":"XMb5tuKPhi8Y"}},{"cell_type":"markdown","source":["13. What is the significance of tensors in PyTorch?\n","\n","-> Tensors are the main building blocks in PyTorch. They are like powerful versions of arrays or matrices and are used to store and handle data.\n","\n","The significance of tensors in PyTorch is:\n","\n","- All data in PyTorch is stored as tensors, whether it's input data, weights, or outputs.\n","- They allow fast mathematical operations, especially when used with GPUs.\n","- They can easily change shape and size, which makes it simple to work with different kinds of data (like images, text, etc.).\n","- Tensors help build and train neural networks, as they are used in every part of the model—from input to output."],"metadata":{"id":"s1DV-MqWhi_P"}},{"cell_type":"markdown","source":["14. What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?\n","\n","-> The main difference is where the tensor is stored and processed:\n","\n","- torch.Tensor: This is a CPU tensor, meaning it is stored in your computer's regular memory and processed by the CPU.\n","\n","- torch.cuda.Tensor:\n","This is a GPU tensor, which means it is stored in the GPU's memory and processed using the GPU. GPU operations are much faster, especially for large models or big data.\n","\n","Example:\n","If you use torch.Tensor, the operations will run on the CPU. If you move your tensor to cuda using .to(\"cuda\") or .cuda(), then it becomes a torch.cuda.Tensor and runs on the GPU."],"metadata":{"id":"HXAJiG9GhjCE"}},{"cell_type":"markdown","source":["15. What is the purpose of the torch.optim module in PyTorch?\n","\n","-> The torch.optim module in PyTorch is used to optimize or improve the model during training.\n","\n","Its main purpose is to update the model's weights after each step of training so the model can make better predictions. It does this by using different optimization algorithms like SGD (Stochastic Gradient Descent), Adam, etc.\n","\n","These optimizers work by:\n","- Taking the loss value (how wrong the model is).\n","- Calculating how to adjust the weights to reduce that loss.\n","- Updating the weights to make the model smarter over time."],"metadata":{"id":"ZN78HowjhjFI"}},{"cell_type":"markdown","source":["16. What are some common activation functions used in neural networks?\n","\n","-> Activation functions are used in neural networks to introduce non-linearity, which helps the model learn complex patterns. Some commonly used activation functions are:\n","\n","- ReLU (Rectified Linear Unit):\n","  - Most popular. It outputs the input if it's positive, otherwise 0.\n","  - Used in hidden layers.\n","\n","- Sigmoid:\n","  - Turns input into a value between 0 and 1.\n","  - Used in binary classification problems.\n","\n","- Tanh (Hyperbolic Tangent):\n","  - Similar to sigmoid but gives output between -1 and 1.\n","  - Better than sigmoid in many cases.\n","\n","- Softmax:\n","  - Turns outputs into probabilities that add up to 1.\n","  - Used in multi-class classification (output layer)."],"metadata":{"id":"7VoWovDYhjIJ"}},{"cell_type":"markdown","source":["17. What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?\n","\n","-> Both torch.nn.Module and torch.nn.Sequential are used to build models in PyTorch, but they are used in different ways:\n","\n","- torch.nn.Module:\n","  - It is the base class for all models in PyTorch.\n","  - It gives you full control to define your model, especially when you need custom behavior.\n","  - You define layers in the __init__() function and the forward pass in the forward() function.\n","  - Use when: your model is complex or you want custom logic in the forward pass.\n","\n","- torch.nn.Sequential:\n","  - It is a shortcut for simple models where layers are stacked one after the other.\n","  - You don't need to write a forward() function manually.\n","  - Use when: your model is simple and the data flows in one straight line through the layers."],"metadata":{"id":"7LtPqyi-hjLN"}},{"cell_type":"markdown","source":["18. How can you monitor training progress in TensorFlow 2.0?\n","\n","-> In TensorFlow 2.0, we can monitor training progress in the following ways:\n","- Using printed output:\n","When we train the model using model.fit(), it shows loss and accuracy after every epoch by default.\n","- Using TensorBoard:\n","TensorBoard is a visual tool that shows graphs, charts, and performance during training. We can connect it by saving training logs and opening them in a browser.\n","- Using validation data:\n","By adding validation data during training, we can see how the model performs on unseen data after each epoch.\n","- Using EarlyStopping and other monitoring tools:\n","These tools help track if the model’s performance is improving or not, and can stop training early if needed."],"metadata":{"id":"qGwRrrNnhjQh"}},{"cell_type":"markdown","source":["19. How does the Keras API fit into TensorFlow 2.0?\n","\n","-> In TensorFlow 2.0, Keras is the main high-level API used to build and train models easily.\n","\n","Earlier, Keras was a separate library, but now it’s fully built into TensorFlow as tf.keras. This means we can use Keras features directly within TensorFlow without installing anything extra.\n","\n","Keras in TensorFlow 2.0 helps with:\n","- Creating models quickly using Sequential or Model class.\n","- Adding layers easily, like Dense, Conv2D, Dropout, etc.\n","- Training models using simple functions like compile(), fit(), and evaluate().\n","- Working well with TensorFlow tools like TensorBoard and tf.data."],"metadata":{"id":"UdqOSv5ahjTp"}},{"cell_type":"markdown","source":["20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0?\n","\n","-> A simple and popular example of a deep learning project using TensorFlow 2.0 is image classification.\n","\n","In this project, you train a model to recognize and classify images into categories — like identifying whether a picture is of a cat or a dog.\n","\n","Here's how the project works:\n","\n","- Collect images of different classes (e.g., cats and dogs).\n","- Preprocess the images so they are all the same size and format.\n","- Build a neural network using TensorFlow and Keras layers.\n","- Train the model on the images so it learns to tell them apart.\n","- Test the model by giving it new images to see how well it performs."],"metadata":{"id":"FIc0b12ahjW-"}},{"cell_type":"markdown","source":["21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch?\n","\n","-> The main advantage of using pre-trained models is that they save time and effort.\n","\n","Pre-trained models are already trained on large datasets (like ImageNet), so they have learned useful patterns. You don't have to start from scratch. Instead, you can:\n","\n","- Use them directly for tasks like image or text classification.\n","- Fine-tune them on your own dataset to get better results with less data.\n","\n","This makes deep learning faster, easier, and more accurate, especially when you don't have a lot of data or computing power."],"metadata":{"id":"7WNrwLymhjau"}},{"cell_type":"markdown","source":["Practical Questions"],"metadata":{"id":"IiD9ExuBribL"}},{"cell_type":"code","source":["#1. How do you install and verify that TensorFlow 2.0 was installed successfully?\n","\n","# Installing tensorflow pip install tensorflow\n","\n","# Verifying\n","\n","import tensorflow as tf\n","\n","print(\"TensorFlow version:\", tf.__version__)\n","\n","# Check if it's using GPU (optional)\n","print(\"Is GPU available:\", tf.test.is_gpu_available())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2N3moyLrk5S","executionInfo":{"status":"ok","timestamp":1752324704189,"user_tz":-330,"elapsed":6926,"user":{"displayName":"Aditi Sahay","userId":"17710093122257315532"}},"outputId":"9eb640d4-c19a-45c0-c32f-44c13eaf16e7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /tmp/ipython-input-1-2217757329.py:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n"]},{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.18.0\n","Is GPU available: True\n"]}]},{"cell_type":"code","source":["#2. How can you define a simple function in TensorFlow 2.0 to perform addition?\n","\n","import tensorflow as tf\n","\n","def add_numbers(a, b):\n","    return tf.add(a, b)\n","\n","# Example use\n","x = tf.constant(5)\n","y = tf.constant(3)\n","\n","result = add_numbers(x, y)\n","print(\"Result:\", result.numpy())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcPJP3K_rrX1","executionInfo":{"status":"ok","timestamp":1752324737621,"user_tz":-330,"elapsed":24,"user":{"displayName":"Aditi Sahay","userId":"17710093122257315532"}},"outputId":"7defdf34-dd6b-46b0-bc67-de904a5f458a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Result: 8\n"]}]},{"cell_type":"code","source":["#3. How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","# Create some dummy input data\n","X = np.random.rand(1000, 5)  # 1000 samples, 5 features each\n","y = np.random.rand(1000, 1)  # 1000 target values (for regression)\n","\n","# Build the model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(10, activation='relu', input_shape=(5,)),  # Hidden layer with 10 neurons\n","    tf.keras.layers.Dense(1)  # Output layer\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mse')  # 'mse' = mean squared error for regression\n","\n","# Train the model\n","model.fit(X, y, epochs=10, batch_size=32)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvgbPKZHrric","executionInfo":{"status":"ok","timestamp":1752324914144,"user_tz":-330,"elapsed":4434,"user":{"displayName":"Aditi Sahay","userId":"17710093122257315532"}},"outputId":"c5fa014c-a0b9-435a-dd86-2855cea19dfd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.5803\n","Epoch 2/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3814\n","Epoch 3/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2475\n","Epoch 4/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1333\n","Epoch 5/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1028\n","Epoch 6/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0926\n","Epoch 7/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0981\n","Epoch 8/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0957\n","Epoch 9/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0861\n","Epoch 10/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0885\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x797adb8f6590>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["#4. How can you visualize the training progress using TensorFlow and Matplotlib\n","\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Create dummy data (1000 samples, 10 features)\n","X = np.random.rand(1000, 10)\n","y = np.random.randint(0, 2, size=(1000, 1))  # binary labels (0 or 1)\n","\n","# Build a simple model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(16, activation='relu', input_shape=(10,)),\n","    tf.keras.layers.Dense(1, activation='sigmoid')  # for binary classification\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model and save the training history\n","history = model.fit(X, y, epochs=20, batch_size=32, validation_split=0.2)\n"],"metadata":{"id":"y9dxCo2prrsp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#5. How do you install PyTorch and verify the PyTorch installation?\n","\n","#Installing pip install torch torchvision\n","#verifying\n","import torch\n","\n","print(\"PyTorch version:\", torch.__version__)"],"metadata":{"id":"7VP1aS1crr5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#6. How do you create a simple neural network in PyTorch?\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","# Create dummy data: 1000 samples, 5 features each\n","X = np.random.rand(1000, 5).astype(np.float32)\n","y = np.random.rand(1000, 1).astype(np.float32)\n","\n","# Convert to PyTorch tensors\n","X_tensor = torch.from_numpy(X)\n","y_tensor = torch.from_numpy(y)\n","\n","# Define the neural network\n","class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.hidden = nn.Linear(5, 10)   # Input layer to hidden layer\n","        self.output = nn.Linear(10, 1)   # Hidden layer to output\n","\n","    def forward(self, x):\n","        x = torch.relu(self.hidden(x))  # Activation function (ReLU)\n","        x = self.output(x)\n","        return x\n","\n","# Create model\n","model = SimpleNN()\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","# Train the model\n","for epoch in range(10):\n","    model.train()\n","\n","    # Forward pass\n","    outputs = model(X_tensor)\n","    loss = criterion(outputs, y_tensor)\n","\n","    # Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}\")\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLqa_i5FrsBS","executionInfo":{"status":"ok","timestamp":1752325048265,"user_tz":-330,"elapsed":8877,"user":{"displayName":"Aditi Sahay","userId":"17710093122257315532"}},"outputId":"20105fb5-7b8c-4422-fb03-5a5fda9c533a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 0.3226\n","Epoch [2/10], Loss: 0.2760\n","Epoch [3/10], Loss: 0.2358\n","Epoch [4/10], Loss: 0.2017\n","Epoch [5/10], Loss: 0.1730\n","Epoch [6/10], Loss: 0.1491\n","Epoch [7/10], Loss: 0.1296\n","Epoch [8/10], Loss: 0.1139\n","Epoch [9/10], Loss: 0.1021\n","Epoch [10/10], Loss: 0.0940\n"]}]},{"cell_type":"code","source":["#7. How do you define a loss function and optimizer in PyTorch?\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Example model with 1 hidden layer\n","model = nn.Sequential(\n","    nn.Linear(5, 10),        # Input layer to hidden layer\n","    nn.ReLU(),               # Activation\n","    nn.Linear(10, 1)         # Hidden layer to output\n",")\n","\n","# 1. Define the Loss Function\n","loss_function = nn.MSELoss()  # Mean Squared Error for regression\n","\n","# 2. Define the Optimizer\n","optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam optimizer with learning rate 0.01\n"],"metadata":{"id":"iTCEIXwcrsLU","executionInfo":{"status":"ok","timestamp":1752326099221,"user_tz":-330,"elapsed":13310,"user":{"displayName":"Aditi Sahay","userId":"17710093122257315532"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["#8. How do you implement a custom loss function in PyTorch?\n","\n","import torch\n","\n","def custom_mae_loss(predictions, targets):\n","    return torch.mean(torch.abs(predictions - targets))\n","\n","# Example predictions and targets\n","pred = torch.tensor([[2.5], [0.5], [2.0]], requires_grad=True)\n","target = torch.tensor([[3.0], [0.0], [2.0]])\n","\n","# Calculate custom loss\n","loss = custom_mae_loss(pred, target)\n","print(\"Custom MAE Loss:\", loss.item())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cuSAVlrTrsT2","executionInfo":{"status":"ok","timestamp":1752326152638,"user_tz":-330,"elapsed":85,"user":{"displayName":"Aditi Sahay","userId":"17710093122257315532"}},"outputId":"4e334287-ec21-4ba5-89c8-e92615152caa"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Custom MAE Loss: 0.3333333432674408\n"]}]},{"cell_type":"code","source":["#9. How do you save and load a TensorFlow model\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","# Step 1: Create dummy training data\n","X = np.random.rand(100, 5)       # 100 samples, 5 features\n","y = np.random.rand(100, 1)       # 100 target values\n","\n","# Step 2: Build the model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(10, activation='relu', input_shape=(5,)),\n","    tf.keras.layers.Dense(1)\n","])\n","\n","# Step 3: Compile the model\n","model.compile(optimizer='adam', loss='mse')\n","\n","# Step 4: Train the model\n","model.fit(X, y, epochs=5, verbose=1)\n","\n","# Step 5: Save the model using the new format\n","model.save('my_model.keras')  # ✅ Add .keras extension\n","\n","# Step 6: Load the saved model\n","loaded_model = tf.keras.models.load_model('my_model.keras')\n","\n","# Step 7: Make predictions\n","predictions = loaded_model.predict(X[:5])\n","\n","# Step 8: Print predictions\n","print(\"Predictions from loaded model:\")\n","print(predictions)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pMfkv1Drsdc","executionInfo":{"status":"ok","timestamp":1752326374307,"user_tz":-330,"elapsed":1844,"user":{"displayName":"Aditi Sahay","userId":"17710093122257315532"}},"outputId":"2d3db87a-984f-41f4-ef7e-8afbccedba45"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 1.0676\n","Epoch 2/5\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9918  \n","Epoch 3/5\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9391 \n","Epoch 4/5\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8823 \n","Epoch 5/5\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8197 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n","Predictions from loaded model:\n","[[-0.17014568]\n"," [ 0.37748888]\n"," [-0.32224816]\n"," [ 0.24167922]\n"," [-0.8576561 ]]\n"]}]}]}